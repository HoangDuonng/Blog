[{"content":"ğŸŒ Why point a domain to hosting? Domain and hosting are the two essentials that keep a website online.\nDomain is the website address. Hosting stores the website data. Why you need to point a domain Connect the domain to hosting so the site appears on the internet. Let people access the site using a memorable address. How it works ğŸ”§ Get nameserver or IP information from your hosting provider. Configure it in your domain management dashboard. Three simplest ways to point a domain to hosting ğŸš€ Point using nameservers Steps:\nLog in to your domain management panel. Select the domain you want to point. Select the domain to point to hosting\nReplace the default nameservers with the hosting provider\u0026rsquo;s nameservers (found in the hosting welcome email). Replace default nameservers with your hosting nameservers\nWait for DNS propagation (minutes to hours, up to 24h). Verify by visiting the domain. Point using IP (A record) Steps:\nLog in to your domain management panel. Select the domain and open DNS settings\nOpen the DNS settings. Add two A records: @ â†’ Hosting IP (from the provider email). www â†’ Hosting IP. Add two A records\nSave changes and wait for DNS propagation (minutes to hours). Point using an intermediate nameserver To point a domain via an intermediate nameserver such as Cloudflare, Namecheap FreeDNS, or Incapsula, follow these steps:\nSteps:\nCreate an account with the intermediate nameserver and confirm required DNS records. In your domain registrar, change the nameservers to the intermediate provider. Wait for propagation. Common issues when pointing a domain to hosting âš ï¸ You may run into issues that prevent your site from working correctly. Understanding these will help you troubleshoot faster.\nğŸš« Wrong hosting domain When registering hosting, the provider asks for your domain. If it is incorrect or mismatched, the website may not work.\nğŸš« Using both methods at once If you already pointed a domain via nameservers, do not switch to IP (A record) at the same time. It can cause DNS conflicts.\nğŸš« Incorrect DNS record type Common DNS record types include:\nA record: Points the domain to the hosting IP. CNAME: Points one domain to another. MX record: Configures email. Entering the wrong record type can break connectivity.\nğŸš« Wrong hosting IP Hosting IPs are long and easy to mistype. Copy directly from the provider email to avoid confusion with a personal IP.\nIf errors occur, double-check your settings and wait for DNS updates to finish.\nVideo guide ğŸ¥ For a visual walkthrough, watch the video below. It covers steps from getting nameserver details to updating settings in your domain manager.\nâ€• Source, F8 Official âœ”ï¸\nConclusion ğŸŒŸ Pointing a domain to hosting is essential for your website to work online. Whether you use nameservers, A records, or an intermediate nameserver, double-check your settings and allow time for DNS propagation. If you encounter issues, review the configuration and try again ğŸ”„. Good luck, and feel free to leave a comment if you need help! ğŸ’¬ğŸ˜Š\n","date":"2025-02-27T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/website/domain-to-hosting-setup.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/website/domain-to-hosting-setup/","title":"Point a Domain to Hosting ğŸŒ"},{"content":"How to upload a website to hosting via File Manager and cPanel from A to Z Uploading a website to hosting is an essential step to bring your site online. It is not just about transferring files but also ensuring everything runs smoothly and securely. This guide walks you through the steps, from preparing files and databases to using the right upload tools.\nKey points to remember Before you start uploading, keep these essentials in mind:\nâœ… What to prepare before uploading: Website files, database, control panel access, and an FTP client like FileZilla.\nâœ… Ways to upload: Choose a reliable host, then use File Manager, FTP, WordPress plugins, SSH, or provider support.\nâœ… Why upload to hosting: Makes your site public, improves security, boosts speed, and simplifies management.\nâœ… Four steps to upload a website:\nUpload website files to public_html via File Manager or FTP. Verify files are in the correct location. Create a database in cPanel, import via phpMyAdmin, and configure the connection. Visit the website to confirm everything works. What do you need before uploading a website? Prepare the following:\nWebsite files: These can be the contents of your old public_html folder, source code, or the latest backup. ğŸ“Œ Note for React/Vue.js deployments\nWhen building a React or Vue.js app, you do not upload the full source code, only the static build output.\nğŸ”¹ Build and zip steps:\nRun the build command: React: 1 npm run build Vue.js: 1 npm run build The output folder is usually build/ (React) or dist/ (Vue.js). Zip the build or dist folder before uploading. ğŸ“¤ Uploading to the server:\nWith cPanel, extract directly in public_html. With SSH/SFTP, upload and unzip using: 1 unzip build.zip -d /var/www/html/ Ensure your Apache/Nginx config points to the folder containing index.html. Database file (if applicable). Control panel access for the new hosting account. FTP client such as FileZilla. To upload, access your hosting control panel via an FTP client like FileZilla. If your site already exists, use the CMS or cPanel backup feature to download it and upload to the new host.\nChoose a reliable hosting provider Quality hosting affects both speed and long-term performance. Choose carefully based on:\nLive support: 24/7 customer support for quick issue resolution. Account control: Full access to cPanel or equivalent tools. Scalability: Ability to upgrade storage, bandwidth, or domains. Clear refund policy: Flexible refunds for testing services. Free add-ons: SSL, scheduled backups, or free migrations. ICANN-accredited domains: Protect your brand with trusted domain registration. Note: Review provider reputation and user feedback on forums or review sites before deciding.\nChoose a website upload method There are five main ways to upload a website depending on your tools and needs:\nUse File Manager File Manager is a web-based file tool built into cPanel or other hosting dashboards.\nPros:\nFree. Easy to use. Cons:\nUpload size limits (usually 256 MB). Can only extract archives within that size limit. Note: For larger files, use FTP and unzip via SSH.\nFigure 1: Access File Manager\nUse FTP FTP (File Transfer Protocol) lets you upload files using an FTP client like FileZilla. This is efficient and has no upload size limit.\nPros:\nNo upload size limits. Faster for large files. Cons:\nRequires an FTP client. Requires FTP credentials from your host. Lower security, use SFTP for better protection. Figure 2: FTP details\nUse WordPress migration plugins If you use WordPress, plugins like All in One WP Migration can move your entire site automatically.\nPros:\nEasy to use with minimal technical knowledge. Simple drag and drop workflow. Cons:\nUpload size limits (usually 256 MB). For larger files, use FTP + SSH. Note: After upload, move files out of subfolders into public_html so the site loads correctly.\nFigure 3: Use WordPress Migration Plugin\nUse SSH (Secure Shell) SSH lets you upload and manage files via command line, ideal for large files or high speed.\nPros:\nFast with no size limits. Extract archives directly on the server. Cons:\nRequires basic command-line skills and SSH access. Figure 4: Upload via SSH\nUse Import Site (automatic importer) Some hosting providers offer an Import Site tool that uploads and extracts a website into public_html.\nPros:\nQuick and easy upload. Minimal technical effort. Cons:\nDepends on whether your host supports the tool. Tip: Ask your hosting provider if they support site import.\nFigure 5: Import Site tool\nAsk hosting support Most providers offer migration help, especially if you are switching hosts.\nPros:\nSaves time and avoids technical mistakes. Done by experts. Cons:\nMay be a paid service. Depends on support availability. Tip: Check the provider\u0026rsquo;s migration policy before requesting support.\nFigure 6: Ask hosting support\nğŸ“Œ Notes after uploading\nMove all data from subfolders into public_html so the site loads correctly. Check file structure and database connections to avoid runtime errors. Choose the best method based on file size, platform, and your skills. Why you should upload a website to hosting Uploading to hosting is required to make your site public, but it also brings major benefits in security, performance, and reliability:\nPublish your website globally When hosted, your website becomes accessible worldwide via your domain name. Otherwise, only your local machine can access it.\nSecurity and data safety Professional hosting provides strong security measures such as SSL certificates, firewalls, and data protection tools. This keeps your site and brand data safe from attacks and breaches.\nSpeed and performance Hosting servers are optimized for high traffic and fast internet speeds, improving page load times and user experience while reducing lag.\nFigure 7: Speed and performance\nStability and reliability Hosting providers manage the hardware and network, ensuring high uptime so your website stays available without long downtime.\nEasy management Hosting dashboards make it easy to back up data, upgrade software, and optimize performance.\nScalability and long-term growth Hosting services scale with your traffic and resource needs, unlike personal machines that struggle with growth.\nFigure 8: Scalability and growth\nIn short, hosting your website improves security, performance, stability, and manageability. It is the foundation for sustainable growth and easy global access.\nStep 1: Choose how to upload website files Method 1: Upload via File Manager in cPanel Method 2: Upload via FTP client After you choose a method, follow the guide below.\n\u0026mdash;Method 1: Upload via File Manager in cPanel\u0026mdash; (Easiest)\nAccess cPanel and follow these steps:\nStep 1: Click File Manager under the Files section.\nChoose File Manager Illustration: Choose File Manager\nChoose File Manager\nStep 2: In File Manager, open the public_html folder.\nOpen public_html Illustration: Open public_html\nOpen public_html\nStep 3: Click Upload inside public_html.\nClick Upload Illustration: Click Upload\nClick Upload\nStep 4: Use Select File to pick files or drag and drop into the upload area.\nSelect file Illustration: Select file\nSelect file\nStep 5: In this example, drag and drop wordpress.zip.\nSelect wordpress zip Illustration: Select wordpress zip (or dist.zip/build.zip)\nSelect wordpress zip\nStep 6: After upload, return to File Manager. The archive appears in public_html. Right-click and choose Extract.\nExtract file Illustration: Extract file\nExtract file\nStep 7: Choose the extraction location. In this example, use /public_html.\nChoose extraction location Illustration: Choose extraction location\nChoose extraction location\nStep 8: After extraction, you will see the files in public_html. This is the website root.\nReturn to the original folder Illustration: Return to the original folder\nReturn to the original folder\nStep 9: The website is now uploaded. Enter your URL in a browser to visit.\nLanguage selection during WordPress setup (If applicable)\n\u0026mdash;Method 2: Upload via FTP client\u0026mdash;\nSome users prefer FTP clients like FileZilla, SmartFTP, CoreFTP, or similar tools. In this guide, we use FileZilla.\nNotes before uploading via FTP:\nYour skills: If you are new to hosting, File Manager is easier. If you are experienced, FTP is faster. Website size: Large websites are easier with FTP because there are no upload limits. Special requirements: If you need special server configuration, check with your hosting provider. Step 1: Get FTP information via FTP Access. If you forgot the password, reset it under Change account password.\nGet FTP Access details Illustration: Get FTP Access details\nGet FTP Access details\nStep 2: Open FileZilla, enter FTP details, and click Quickconnect.\nClick Quickconnect Illustration: Click Quickconnect\nClick Quickconnect\nStep 3: After connecting, locate your website files and drag them from the left pane to the right pane, targeting public_html. Unzip archives before upload because FTP cannot extract files.\nDrag and drop files Illustration: Drag and drop files\nDrag and drop files\nStep 4: You can also upload archives via FTP, then extract using File Manager.\nUpload archives via FTP Illustration: Upload archives via FTP\nUpload archives via FTP\nStep 5: After upload, enter the website URL in a browser to confirm installation or customize it.\nStep 2: Verify files are inside public_html After uploading, check that all files are in public_html. If you extracted a backup into a subfolder, users would need to visit example.com/something instead of example.com. Fix this by moving files:\nOpen the folder with the website files. Select all files, right-click, and choose Move. Select public_html and click Proceed. If your site has been running already, upload the database as well.\nAfter confirming file placement, open your domain in a browser. If DNS is not updated, you can:\nEdit the hosts file to simulate DNS changes. Use online tools to check DNS status. Install browser plugins for virtual hosts. If you need to move a site from a subfolder into public_html, use File Manager or FTP. Remember to upload the database if needed.\nStep 3: Upload the database to hosting Perform this step only if your website uses a database.\nCreate a database in cPanel Create a new database in MySQL Databases and record:\nMySQL Database MySQL User MySQL Host MySQL Password Create a new database\nOpen phpMyAdmin In phpMyAdmin, import your MySQL database. If importing into an existing database, clear it first to avoid errors.\nOpen phpMyAdmin\nImport the database Go to the Import tab and upload your SQL file (.sql, .sql.zip, or .sql.gz). Click Choose File, then Go to start. When phpMyAdmin shows Import has been successfully finished, 302 queries executed, the upload is done.\nImport database\nUpdate configuration for database connection After upload, open your PHP configuration file and fill in host, database name, username, and password. The file name and location depend on your software. For WordPress, the file is wp-config.php in public_html.\nâš  Notes:\nLarge databases should be split into smaller files to speed up uploads. If your database contains special characters, convert them to ASCII before upload. If import errors occur, check for corruption. Create a fresh database and try again. After uploading, test your website to ensure everything works. Update configuration for database connection After uploading, open the PHP config file to enter the host, database name, username, and password.\nThe file name and location depend on your software. For example, WordPress uses wp-config.php in public_html.\nStep 4: Check if the website is stable To ensure stability after upload and domain mapping, perform the following checks:\nğŸ” Check website access Access via domain or IP: If it loads, the site is live. Wait for DNS propagation: New DNS changes can take 24 hours. Check immediately using: ğŸ–¥ï¸ Hosts file: Edit the hosts file to simulate DNS changes. ğŸŒ Online tools: Use online DNS checkers. ğŸ”Œ Browser plugins: Use plugins for virtual hosts. ğŸ› ï¸ Test website functions Visit multiple pages and verify links. Ensure features work as expected. âš¡ Check load speed Use Google PageSpeed Insights or GTmetrix. ğŸš¨ Check for errors 404: Page not found. 500: Hosting server error. 503: Server maintenance. ğŸŒ Test across browsers and devices Try Chrome, Firefox, Safari, Edge on desktop, mobile, tablet. â³ Test at different times Performance can vary throughout the day. ğŸ‘‰ If issues appear and you are unsure how to fix them, contact your hosting provider. ğŸš€\nğŸ“Œ Conclusion Uploading a website to hosting is a key step for stable online operation. By preparing correctly and following the steps above, you ensure your website is ready to serve users effectively.\nğŸ’¡ If you have questions or need help, leave a comment below. I will respond soon.\nThanks for reading! ğŸš€\n","date":"2025-02-26T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/website/upload-website-on-hosting.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/website/how-to-deploy-a-website/","title":"Deploy a Website to Hosting the Simplest Way (HTML/CSS or React/Vue.js) ğŸ”¥"},{"content":"ğŸ“Š Application Monitoring Application monitoring is the continuous tracking and analysis of software applications to ensure they run optimally, detect incidents, and provide deep insights into system performance. Monitoring covers critical metrics such as:\nâ³ Response time âŒ Error rate ğŸ–¥ï¸ Resource usage (CPU, RAM, Disk) ğŸ”„ Transaction performance Application monitoring tools collect and analyze data to detect anomalies, alert on potential issues, and provide a complete view of application behavior. This allows teams to proactively resolve incidents, optimize performance, and improve user experience.\nğŸ” Jaeger - Distributed tracing tool Jaeger is an open-source distributed tracing system developed by Uber, designed to track and troubleshoot complex microservices architectures.\nğŸ”¹ Key features: ğŸŒ Distributed request tracing ğŸ” Service dependency analysis ğŸ“Š Root cause identification ğŸ› ï¸ OpenTracing support for easy integration ğŸ”¹ Example: Running Jaeger with Docker 1 2 3 4 5 6 7 8 9 10 11 docker run -d --name jaeger \\ -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \\ -p 5775:5775/udp \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 14268:14268 \\ -p 14250:14250 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.37 After installation, open Jaeger UI at http://localhost:16686.\nğŸ“Œ References:\nğŸ“– Jaeger documentation ğŸ› ï¸ GitHub - jaegertracing ğŸŒ New Relic - Application performance monitoring New Relic is a cloud observability platform that provides a comprehensive view of software and infrastructure. It supports real-time performance monitoring, data analysis, and automated alerts.\nğŸ”¹ Key features: ğŸ“ˆ Application performance monitoring (APM) ğŸ” Log analysis and error tracing ğŸš€ Web and mobile user experience monitoring ğŸ¤– AI-powered analytics for incident detection ğŸ”¹ Example: Installing New Relic Agent in Node.js 1 npm install newrelic --save Then add require('newrelic') at the top of your main file:\n1 2 3 4 5 require(\u0026#39;newrelic\u0026#39;); const express = require(\u0026#39;express\u0026#39;); const app = express(); app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; res.send(\u0026#39;Hello, New Relic!\u0026#39;)); app.listen(3000, () =\u0026gt; console.log(\u0026#39;App running on port 3000\u0026#39;)); ğŸ“Œ References:\nğŸŒ New Relic website ğŸ¥ New Relic platform demo ğŸ¶ Datadog - Full-stack monitoring solution Datadog is a monitoring and analytics platform for large-scale applications. It covers infrastructure monitoring, application performance, logs management, and user experience.\nğŸ”¹ Key features: ğŸ”— 400+ integrations with DevOps tools ğŸ“Š Unified dashboards for full system visibility âš ï¸ Intelligent alerting ğŸ“¡ Cloud-native monitoring support ğŸ”¹ Example: Installing Datadog Agent 1 2 DD_AGENT_MAJOR_VERSION=7 DD_API_KEY=\u0026lt;YOUR_API_KEY\u0026gt; \\ DD_SITE=\u0026#34;datadoghq.com\u0026#34; bash -c \u0026#34;$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script.sh)\u0026#34; After installation, access the Datadog dashboard to view metrics.\nğŸ“Œ References:\nğŸŒ Datadog website ğŸ“– Datadog documentation ğŸ¯ Conclusion Application monitoring is crucial for ensuring system performance and reliability. Tools such as Jaeger, New Relic, and Datadog provide comprehensive solutions to track, analyze, and optimize software systems effectively. Choosing the right tool helps you manage applications better, detect issues early, and improve user experiences.\nğŸš€ Deploy monitoring to optimize your application performance!\nğŸ‘‰ Next step: Learn about Artifacts in software development. Artifacts are the files or products produced during the development and deployment process.\n","date":"2025-02-25T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-eighteen.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-eighteen/","title":"Application Monitoring ğŸ“Š"},{"content":"ğŸ—ï¸ What are Artifacts? Artifacts are products generated throughout the software development lifecycle. They can include:\nğŸ“œ Source code: Files that contain application logic. ğŸ—ï¸ Binaries: Compiled executables or libraries. ğŸ“– Documentation: User guides, API specs. âš™ï¸ Configuration files: Settings needed to run the application. ğŸ› ï¸ Test results: Reports from testing pipelines. Managing artifacts helps ensure consistency, traceability, and more efficient software delivery.\nğŸ¢ Popular Artifact Management Tools ğŸš€ 1. Artifactory Artifactory is a DevOps solution for storing, managing, and distributing artifacts. It supports many formats such as Docker, npm, Maven, Python, Go, and more.\nğŸ”§ Install Artifactory with Docker: 1 2 3 4 5 # Pull Artifactory image docker pull releases-docker.jfrog.io/jfrog/artifactory-oss:latest # Run container docker run --name artifactory -d -p 8081:8081 releases-docker.jfrog.io/jfrog/artifactory-oss:latest After installation, you can access the web interface at http://localhost:8081.\nğŸ“¦ 2. Nexus Repository Manager Nexus is one of the most popular tools for binary artifacts, especially in Java environments.\nğŸ—ï¸ Install Nexus on Linux: 1 2 3 4 wget https://download.sonatype.com/nexus/3/latest-unix.tar.gz tar -xvf latest-unix.tar.gz cd nexus-3.* ./bin/nexus start After it starts, you can access Nexus at http://localhost:8081.\nâ˜ï¸ 3. Cloudsmith Cloudsmith is a cloud-based artifact management platform that supports many package formats such as Docker, Helm, npm, and pip.\nâš¡ Upload packages to Cloudsmith: 1 2 3 4 5 # Install Cloudsmith CLI pip install cloudsmith-cli # Push a package to the repository cloudsmith push python my-org/my-repo my-package-1.0.0.tar.gz Cloudsmith simplifies package distribution and management.\nğŸ¯ Conclusion Artifact management is critical in the software development process. Using tools like Artifactory, Nexus, and Cloudsmith ensures organized, secure, and efficient storage and deployment. Depending on project needs, you can choose the tool that best fits your DevOps workflow.\nğŸ› ï¸ What tools do you use to manage artifacts? Share your experience!\nğŸ‘‰ Next step: Learn about GitOps - the process of provisioning and configuring resources (servers, networks, storage, accounts) so that systems or applications can operate effectively.\n","date":"2025-02-25T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-nineteen.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-nineteen/","title":"Artifact Management in Software Development ğŸ¢"},{"content":"Introduction Cloud design patterns are reusable solutions for common problems in cloud architectures. These patterns address scalability, reliability, security, and performance challenges in distributed systems.\nThey provide best practices for designing and deploying cloud applications, including data management, messaging, resiliency, and deployment. Common examples include:\nCircuit Breaker: Prevents cascading failures by temporarily breaking connections after repeated errors. CQRS (Command Query Responsibility Segregation): Separates read and write operations to improve performance. Sidecar Pattern: Splits auxiliary application components into separate processes or containers for more flexibility. ğŸ”¹ Availability Availability is the percentage of time a system operates as expected, often called uptime. It can be affected by hardware or software failures, infrastructure issues, cyberattacks, or excessive load.\nCloud providers typically define service level agreements (SLA) that specify guaranteed uptime. For example, a company might promise 99.99% availability.\nğŸ”¹ Example: A system that guarantees 99.99% uptime can only be down for 52 minutes per year.\nğŸ”¹ Data Management Data management is a key factor in cloud applications and influences most quality attributes. Data is often stored in multiple locations to improve performance, scale, or availability. This introduces challenges such as:\nMaintaining data consistency when synchronizing across servers. Securing data during storage, transit, and access. Scalability to handle growth demands. ğŸ”¹ Example: Banking systems must ensure transactions remain consistent across data centers to avoid incorrect account balances.\nğŸ”¹ Design and Implementation Good design helps systems stay maintainable, consistent, and reusable across multiple scenarios. Decisions made during design and implementation directly affect cost and overall cloud application quality.\nKey design principles:\nConsistency: Components should follow a defined structure. Scalability: Systems must handle high traffic without performance degradation. Reusability: Components should be usable across different applications. ğŸ”¹ Example: An e-commerce system uses microservices architecture to scale individual services independently (payments, cart, product search).\nğŸ”¹ Management and Monitoring DevOps management and monitoring covers the lifecycle from planning, development, testing, deployment, to operations. A solid monitoring system tracks the status of applications, services, and infrastructure in production.\nğŸ”¹ Key monitoring components:\nReal-time streaming: Observe systems in real time. Historical replay: Store history for incident analysis. Visualization: Present data visually to evaluate system health. ğŸ”¹ Example: Using Prometheus + Grafana to monitor Kubernetes container performance.\nğŸ”¥ Conclusion Cloud design patterns optimize system architecture by providing solutions for common challenges such as performance, security, and scalability. Choosing the right patterns helps businesses build resilient, flexible, and maintainable systems.\nâœ… Wrap-up: You have completed the DevOps journey, combining Development and Operations to speed up software delivery, improve reliability, and optimize workflows. Thank you for following along, and we hope this knowledge supports your next steps! ğŸš€\n","date":"2025-02-25T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-twenty-two.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-twenty-two/","title":"Cloud Design Patterns ğŸŒŸ"},{"content":"Introduction GitOps is a method for managing infrastructure and application deployments by using Git as the single source of truth. It automates deployments, ensures consistency, and improves change tracking.\nGitOps extends DevOps practices by applying version control and CI/CD principles to infrastructure management. Instead of manual changes, every update flows through pull requests and is automatically synchronized with live environments.\nğŸš€ Benefits of GitOps âœ… Version control: Every change is tracked in Git, making it easy to audit or roll back when needed.\nâœ… Automated deployments: Tools like ArgoCD or FluxCD sync environments automatically.\nâœ… Improved security: All changes go through Git, preventing direct access to production systems.\nâœ… High resilience: Systems can recover quickly by re-applying Git state after incidents.\nâœ… Better team collaboration: Changes are reviewed via pull requests, enabling smoother teamwork.\nğŸ› ï¸ Popular GitOps Tools ArgoCD - Powerful continuous deployment ArgoCD is a continuous deployment (CD) tool for Kubernetes. It automates deployments by watching application state in Git and syncing it with the live cluster.\nğŸ”¹ Key features:\nAutomatic sync between Git and environment state. Visual web UI for deployment status. Supports Helm, Kustomize, and other configuration tools. ğŸ”¹ Example ArgoCD application\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion: argoproj.io/v1alpha1 kind: Application metadata: name: my-app namespace: argocd spec: destination: namespace: default server: https://kubernetes.default.svc source: repoURL: https://github.com/my-org/my-repo.git targetRevision: HEAD path: manifests syncPolicy: automated: selfHeal: true prune: true FluxCD - Automated deployment management FluxCD is a GitOps tool that deploys applications to Kubernetes by watching Git repositories and updating clusters automatically.\nğŸ”¹ Key features:\nTracks Git repositories and deploys automatically. Supports Helm, Kustomize, and many CI/CD systems. Provides automatic container image updates. ğŸ”¹ Example FluxCD configuration:\n1 2 3 4 5 6 7 8 9 10 apiVersion: source.toolkit.fluxcd.io/v1beta1 kind: GitRepository metadata: name: my-app-repo namespace: flux-system spec: interval: 1m0s url: https://github.com/my-org/my-repo.git ref: branch: main ğŸ”¥ ArgoCD vs FluxCD Feature ArgoCD FluxCD Visual UI âœ… Yes âŒ No Helm support âœ… Yes âœ… Yes Automatic container image updates âŒ No âœ… Yes Canary/Rollback deployments âœ… Yes âœ… Yes ğŸ“Œ Conclusion GitOps simplifies application deployments by using Git as the central control layer. With tools like ArgoCD and FluxCD, teams can automate deployments, ensure consistency, and improve system resiliency.\nğŸ”— References:\nğŸ“– ArgoCD documentation ğŸ“– FluxCD documentation ğŸ“˜ GitOps guide Have you tried GitOps in your projects? Share your experience! ğŸš€\nğŸ‘‰ Next step: Learn about Service Mesh - a software infrastructure layer that manages communication between services in microservices systems. It provides load balancing, security, observability, traffic control, and fault handling so services can communicate efficiently without changing application code.\n","date":"2025-02-25T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-twenty.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-twenty/","title":"GitOps - Automated Deployment with Git ğŸŒŸ"},{"content":"ğŸ“Œ Introduction Service Mesh is a software infrastructure layer that manages communication between services in microservices systems. It provides load balancing, security, observability, traffic control, and fault handling, enabling services to communicate efficiently without changing application code.\nPopular Service Mesh tools include Istio, Linkerd, and Consul.\nğŸš€ Benefits of Service Mesh âœ… Automatic service-to-service communication management - No application code changes required. âœ… Enhanced security - TLS encryption, service authentication, RBAC policies. âœ… Performance optimization - Smart load balancing and traffic control. âœ… Comprehensive observability - Logs, metrics, and tracing for monitoring. âœ… High resilience - Automatic fault detection and recovery.\nğŸ› ï¸ Popular Service Mesh Tools 1ï¸âƒ£ Istio - The most powerful solution Istio is an open-source Service Mesh platform that provides control, security, and observability for Kubernetes services.\nğŸ”¹ Key features:\nmTLS support for secure service communication. Smart load balancing, retries, and timeouts. API gateway management and access policies. ğŸ”¹ Istio Gateway example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: my-gateway spec: selector: istio: ingressgateway servers: - port: number: 80 name: http protocol: HTTP hosts: - \u0026#34;example.com\u0026#34; ğŸ“– Istio documentation\n2ï¸âƒ£ Linkerd - Lightweight and fast Linkerd is a lightweight Service Mesh optimized for Kubernetes, designed to reduce latency and resource usage.\nğŸ”¹ Key features:\nAutomatic TLS (mTLS) for all communications. Built-in tracing and metrics. Quick installation with a single CLI command. ğŸ”¹ Linkerd configuration example:\n1 2 3 4 5 6 7 8 9 10 11 apiVersion: linkerd.io/v1alpha2 kind: ServiceProfile metadata: name: my-service.default.svc.cluster.local spec: routes: - name: \u0026#34;GET /health\u0026#34; condition: method: GET pathRegex: \u0026#34;/health\u0026#34; isRetryable: true ğŸ“– Linkerd documentation\n3ï¸âƒ£ Consul - Service Mesh with service discovery Consul is not only a Service Mesh, but also provides service discovery, configuration management, and secure communication between services.\nğŸ”¹ Key features:\nService discovery for Kubernetes and traditional systems. Integration with Envoy Proxy for traffic management. Supports multi-cluster and hybrid cloud environments. ğŸ”¹ Consul service registration example:\n1 2 3 4 5 6 7 { \u0026#34;service\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;port\u0026#34;: 8080, \u0026#34;connect\u0026#34;: { \u0026#34;sidecar_service\u0026#34;: {} } } } ğŸ“– Consul documentation\nğŸ”¥ Service Mesh Comparison Feature Istio Linkerd Consul Visual UI âœ… Yes âŒ No âœ… Yes mTLS support âœ… Yes âœ… Yes âœ… Yes High performance âš ï¸ Needs tuning âœ… Fast âš ï¸ Moderate Service discovery âŒ No âŒ No âœ… Yes ğŸ“Œ Conclusion Service Mesh simplifies managing communication between microservices, ensuring security, observability, and high performance.\nğŸ’¡ If you need the most powerful solution, try Istio. ğŸ’¡ If you prioritize performance and ease of setup, choose Linkerd. ğŸ’¡ If you need service discovery and multi-cloud, consider Consul.\nğŸ“– References: ğŸ”— Istio documentation ğŸ”— Linkerd documentation ğŸ”— Consul documentation\nHave you tried any Service Mesh deployments? Share your experience! ğŸš€\nğŸ‘‰ Final step: Learn about Cloud Design Patterns - a set of proven patterns for building efficient, flexible, and scalable cloud applications. They address common challenges like high availability, fault tolerance, elastic scaling, and security in cloud environments.\n","date":"2025-02-25T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-twenty-one.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-twenty-one/","title":"Service Mesh - Managing Microservices Communication ğŸŒ"},{"content":"ğŸ” What is CI/CD? CI/CD (Continuous Integration/Continuous Deployment) is a methodology that helps automate the software development process, reducing errors, speeding up deployment, and improving product quality.\nContinuous Integration (CI): Continuous integration, helps detect errors early by automatically testing whenever there are changes in the source code. Continuous Deployment (CD): Continuous deployment, ensures software is released automatically and quickly. ğŸŒŸ Popular CI/CD Tools ğŸ”§ Jenkins Jenkins is a popular open-source automation server that helps build, test, and deploy software automatically.\nğŸ“Œ Key Features:\nSupports many plugins, easy integration with DevOps tools. Intuitive web interface, easy to configure. Supports both Windows and Linux environments. ğŸ’¡ Example: Configuring a simple pipeline in Jenkinsfile\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 pipeline { agent any stages { stage(\u0026#39;Build\u0026#39;) { steps { echo \u0026#39;Building the application...\u0026#39; } } stage(\u0026#39;Test\u0026#39;) { steps { echo \u0026#39;Running tests...\u0026#39; } } stage(\u0026#39;Deploy\u0026#39;) { steps { echo \u0026#39;Deploying the application...\u0026#39; } } } } ğŸ“– Useful Resources:\nğŸ”— Jenkins Homepage ğŸ¥ Jenkins Tutorial from A-Z ğŸ”„ CircleCI CircleCI is a powerful CI/CD platform that supports many programming languages and integrates well with GitHub and Bitbucket.\nğŸ“Œ Key Features:\nSupports parallel builds to increase processing speed. Good integration with Docker and Kubernetes. Available in cloud and self-hosted versions. ğŸ’¡ Example: Configuring a CircleCI pipeline in .circleci/config.yml\n1 2 3 4 5 6 7 8 9 version: 2.1 jobs: build: docker: - image: circleci/node:14 steps: - checkout - run: npm install - run: npm test ğŸ“– Useful Resources:\nğŸ”— CircleCI Homepage ğŸ¥ CircleCI Tutorial Video ğŸ› ï¸ GitLab CI/CD GitLab CI/CD is a built-in system in GitLab that allows automating testing and deployment processes right within the Git repository.\nğŸ“Œ Key Features:\nSupports full pipeline automation from build, test to deploy. Built into GitLab, no external tools needed. Supports running pipelines on Docker containers. ğŸ’¡ Example: Configuring GitLab CI/CD pipeline in .gitlab-ci.yml\n1 2 3 4 5 6 7 8 9 10 stages: - build - test - deploy test: stage: test script: - npm install - npm test ğŸ“– Useful Resources:\nğŸ”— GitLab Homepage ğŸ¥ GitLab CI/CD Tutorial âš¡ GitHub Actions GitHub Actions is a CI/CD tool integrated directly into GitHub, helping automate testing and deployment processes whenever there are changes in the repository.\nğŸ“Œ Key Features:\nTightly integrated with GitHub, easy workflow setup. Supports many operating systems and programming languages. Can use marketplace with thousands of available actions. ğŸ’¡ Example: GitHub Actions workflow in .github/workflows/main.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 name: Node.js CI on: [push, pull_request] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Setup Node.js uses: actions/setup-node@v3 with: node-version: 14 - run: npm install - run: npm test ğŸ“– Useful Resources:\nğŸ”— GitHub Actions Homepage ğŸ¥ GitHub Actions Tutorial Video ğŸ¯ Conclusion CI/CD helps accelerate the software development process, minimize errors, and improve product quality. Depending on your needs and working environment, you can choose Jenkins, CircleCI, GitLab CI/CD, or GitHub Actions to deploy your CI/CD system. ğŸš€\nğŸ‘‰ Next step: Learn about Secret Management - the process of storing, managing, and protecting sensitive information such as passwords, API keys, certificates, and access tokens to prevent data leakage and ensure system security. ğŸ’¡\n","date":"2025-02-24T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-thirteen.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-thirteen/","title":"CI/CD - Continuous Integration and Continuous Deployment ğŸš€"},{"content":"ğŸ”§ Configuration Management Configuration management is the process of managing and maintaining consistency of components within an information technology system. In the software field, it includes monitoring, tracking, and managing system configuration changes throughout the product lifecycle. Applying configuration management helps increase synchronization, reduce error risks, and ensure compliance with standards in CI/CD (Continuous Integration and Continuous Deployment) processes.\nğŸŒ Popular Configuration Management Tools ğŸš€ Ansible Ansible is an open automation tool, primarily used for configuration management, application deployment, and task automation.\nğŸ”„ Features:\nUses YAML (playbooks) to define desired states. Works without requiring agent installation. Suitable for small to large scale environments. ğŸ’¡ Ansible usage example:\n1 2 3 4 5 6 7 8 9 10 11 12 - name: Install and start Nginx hosts: all become: yes tasks: - name: Install Nginx apt: name: nginx state: present - name: Start Nginx service: name: nginx state: started ğŸ“– Useful free resources:\nğŸ“š Complete Ansible Course for Beginners ğŸ”— Official Ansible Website ğŸ¥ Ansible in 100 Seconds ğŸŒŸ Chef Chef (now part of Progress Chef) is one of the first configuration management tools. It uses Ruby language and emphasizes idempotence (ensuring running n times produces the same result).\nğŸ”„ Features:\nClient/server based. Has Chef-Solo for standalone deployment. Suitable for enterprise environments. ğŸ’¡ Chef usage example:\n1 2 3 4 5 6 7 package \u0026#39;nginx\u0026#39; do action :install end service \u0026#39;nginx\u0026#39; do action [:enable, :start] end ğŸ“– Useful free resources:\nğŸ”— Official Chef Website ğŸ“š Chef Tutorial ğŸ¥ Chef Tutorial Video ğŸ° Puppet Puppet is a declarative configuration management tool that operates in a client/server model and supports multiple operating systems.\nğŸ”„ Features:\nLarge scale management. Periodic configuration checking and application. Integration with many DevOps tools. ğŸ’¡ Puppet usage example:\n1 2 3 4 5 6 7 8 package { \u0026#39;nginx\u0026#39;: ensure =\u0026gt; installed, } service { \u0026#39;nginx\u0026#39;: ensure =\u0026gt; running, enable =\u0026gt; true, } ğŸ“– Useful free resources:\nğŸ“š Complete Puppet Course ğŸ”— Official Puppet Website ğŸ¥ Great Puppet Articles ğŸ‰ Conclusion Configuration management is an important element in the DevOps process, helping ensure consistent system operation, minimize errors, and enhance reliability. Depending on needs and scale, businesses can choose Ansible, Chef, or Puppet to manage infrastructure effectively.\nğŸ‘‰ Next step: Learn about Continuous Integration and Continuous Deployment (CI/CD), which is an automation process in software development that helps integrate, test, and deploy applications continuously.\n","date":"2025-02-24T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-twelve.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-twelve/","title":"Configuration Management ğŸ”§"},{"content":"ğŸ” What is Container Orchestration? Container orchestration is the process of managing and automating the container lifecycle, including deployment, scaling, and networking across multiple servers. It is critical for running complex applications in production environments.\nBy using tools like Kubernetes, Docker Swarm, and Apache Mesos, organizations can ensure high availability, scalability, and reliability for their applications. Container orchestration automates operational tasks and provides a strong foundation for microservices, cloud-native development, and DevOps.\nğŸ“š Free resources:\nğŸ“¦ What is Container Orchestration? ğŸš€ What is Kubernetes? ğŸ³ Docker Swarm ğŸ¥ Kubernetes introduction â˜¸ï¸ Kubernetes Kubernetes is the most popular open-source platform for container management. It allows container deployment across multiple servers, defining availability, deployment logic, and scaling through YAML.\nKubernetes originated from Borg, Google\u0026rsquo;s internal platform, and has become a critical skill for DevOps engineers. Many organizations now have Platform Engineering teams dedicated to supporting Kubernetes for product teams.\nğŸ“š Free resources:\nğŸ—ºï¸ In-depth Kubernetes roadmap ğŸŒ Official Kubernetes website ğŸ“– Kubernetes overview ğŸ¥ Complete Kubernetes course - beginner to advanced ğŸ“Œ Example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion: apps/v1 kind: Deployment metadata: name: my-app spec: replicas: 3 selector: matchLabels: app: my-app template: metadata: labels: app: my-app spec: containers: - name: my-app image: my-app-image:latest â˜ï¸ GKE / EKS / AKS ğŸ”¹ GKE - Google Kubernetes Engine Google Kubernetes Engine (GKE) is a managed Kubernetes service by Google Cloud. It helps deploy, manage, and scale container applications with Kubernetes without managing the cluster manually.\nğŸ”¹ EKS - Amazon Elastic Kubernetes Service Amazon Elastic Kubernetes Service (EKS) is a Kubernetes service provided by AWS. It automatically manages the Kubernetes control plane and integrates with other AWS services.\nğŸ”¹ AKS - Azure Kubernetes Service Azure Kubernetes Service (AKS) is Microsoft Azureâ€™s Kubernetes service. AKS supports monitoring, security, autoscaling, and integration with Azure DevOps.\nğŸ“š Free resources:\nâ˜ï¸ Google Kubernetes Engine (GKE) ğŸŸ§ Amazon Elastic Kubernetes Service (EKS) ğŸ”µ Azure Kubernetes Service (AKS) ğŸ¥ AWS EKS tutorial ğŸ¥ What is Google Kubernetes Engine? ğŸš€ ECS / Fargate ECS is a container management service that runs on AWS EC2, giving you control over the server infrastructure.\nFargate is a serverless container service that runs containers without managing servers or clusters.\nğŸ“š Free resources:\nğŸ“„ AWS Fargate documentation ğŸ“„ AWS ECS documentation ğŸ¥ AWS Fargate overview ğŸ¥ AWS ECS tutorial ğŸ“Œ Example:\n1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;family\u0026#34;: \u0026#34;my-task\u0026#34;, \u0026#34;containerDefinitions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;my-container\u0026#34;, \u0026#34;image\u0026#34;: \u0026#34;my-container-image:latest\u0026#34;, \u0026#34;memory\u0026#34;: 512, \u0026#34;cpu\u0026#34;: 256 } ] } ğŸ³ Docker Swarm Docker Swarm is a cluster of Docker nodes (physical or virtual machines). The cluster is managed by a swarm manager, and the participating machines are nodes.\nğŸ“š Free resources:\nğŸ“„ Docker Swarm documentation ğŸ”§ Manage Docker Swarm with Portainer ğŸ“¦ Docker Swarm with GlusterFS storage ğŸ¥ Docker Swarm introduction | step-by-step ğŸ“Œ Example:\n1 2 3 4 5 # Initialize Swarm $ docker swarm init # Deploy a service on Swarm $ docker service create --name web -p 80:80 nginx âœ… Conclusion Container orchestration plays a vital role in managing containerized applications, helping simplify operations, optimize resources, and improve availability. Tools such as Kubernetes, Docker Swarm, ECS, and Fargate offer flexible solutions for modern enterprises. Choosing the right tool enables organizations to maximize the power of containerization and cloud computing. ğŸš€\nğŸ‘‰ Next step: Learn about Application Monitoring - tracking, measuring, and analyzing application performance, status, and behavior to detect incidents, optimize performance, and ensure a great user experience. Popular tools include Prometheus, Grafana, Datadog, and New Relic for collecting data from applications, servers, and infrastructure to provide alerts and detailed reports.\n","date":"2025-02-24T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-seventeen.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-seventeen/","title":"Container Orchestration ğŸš¢"},{"content":"ğŸ” What is Infrastructure Monitoring? Infrastructure monitoring is the process of tracking the performance and status of systems to detect incidents early and optimize operations. This is a broad field with many tools, each with its own strengths and weaknesses. Understanding these tools helps you choose the right solution for your monitoring goals.\nğŸš€ Popular Monitoring Tools Grafana ğŸ“ Overview: Grafana is an open-source web application for data analysis and visualization. It connects to many data sources such as time series databases, relational databases, and cloud services.\nğŸ”¹ Key features:\nPowerful visualization with many chart types. Supports a wide range of plugins. Real-time alerting system. User authentication and role-based access control. ğŸ“Œ Example: Use Grafana to monitor CPU and RAM usage to detect and handle overload incidents.\nğŸ“š Useful resources:\nğŸ”— Grafana homepage ğŸ“– Installation and usage guides Prometheus ğŸ“ Overview: Prometheus is an open-source monitoring and alerting tool, especially well-suited for microservices and containerized systems like Kubernetes.\nğŸ”¹ Key features:\nMulti-dimensional data model. Powerful PromQL query language. Pull-based data collection model. Smart alert management with Alertmanager. ğŸ“Œ Example: Use Prometheus to collect and analyze API request counts to identify peak traffic and optimize performance.\nğŸ“š Useful resources:\nğŸ”— Prometheus homepage ğŸ¥ Prometheus introduction Zabbix ğŸ“ Overview: Zabbix is an open-source monitoring platform that supports comprehensive tracking for system components such as servers, networks, applications, and services.\nğŸ”¹ Key features:\nMultiple data collection methods: Agent, SNMP, IPMI, custom scripts. Real-time alerts and notifications. Detailed dashboards and reporting system. Scales well for large environments. ğŸ“Œ Example: Use Zabbix to monitor server status, detect downtime, and send alerts immediately.\nğŸ“š Useful resources:\nğŸ”— Zabbix homepage ğŸ“– Zabbix documentation âœ… Conclusion Each monitoring tool has its own strengths:\nGrafana: Strong data visualization. Prometheus: Great for container and microservices environments. Zabbix: End-to-end monitoring for large systems. Depending on your specific needs, you can combine multiple tools to build an optimal monitoring system. ğŸš€\nğŸ‘‰ Next step: Learn about Logs Management - the process of collecting, storing, processing, and analyzing logs from systems, applications, and devices to track activity, detect incidents, ensure security, and support faster troubleshooting.\n","date":"2025-02-24T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-fifteen.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-fifteen/","title":"Infrastructure Monitoring ğŸ“Š"},{"content":"ğŸ”¹ What is Provisioning? Provisioning refers to the process of setting up and configuring the necessary IT infrastructure to support an application or service. This includes allocating and preparing resources such as servers, storage, networking, and software environments.\nWhile provisioning can be done manually, in modern DevOps, this process is typically automated using tools like Terraform, Pulumi, CloudFormation. Using Infrastructure-as-Code (IaC) helps define the entire provisioning process in version-controlled script files, ensuring consistency, reducing human errors, and improving scalability and disaster recovery.\nğŸ“– Free resources to learn:\nğŸ“„ What is provisioning? - RedHat ğŸ“„ What is provisioning? - IBM ğŸ¥ Open Answers: What is provisioning? ğŸ—ï¸ Terraform - Powerful IaC Solution Terraform is an open-source Infrastructure-as-Code (IaC) tool developed by HashiCorp that helps define, deploy, and manage infrastructure on multi-cloud or on-premises environments using declarative configuration files.\nğŸŒŸ Benefits of Using Terraform âœ… Multi-platform support: AWS, Azure, Google Cloud, Kubernetes, etc. âœ… State management: Helps track infrastructure resources. âœ… Scalability and reusability: Easy to modularize configurations. âœ… CI/CD integration: Automates infrastructure deployment.\nğŸ”¨ Example: Creating an EC2 instance on AWS 1 2 3 4 5 6 7 8 9 10 11 provider \u0026#34;aws\u0026#34; { region = \u0026#34;us-east-1\u0026#34; } resource \u0026#34;aws_instance\u0026#34; \u0026#34;web\u0026#34; { ami = \u0026#34;ami-12345678\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; tags = { Name = \u0026#34;Terraform-Instance\u0026#34; } } ğŸ“– Free resources to learn:\nğŸ“ Detailed Terraform Roadmap ğŸ¥ Complete Terraform Course ğŸ“„ Official Terraform Documentation ğŸ“– How to Scale Your Terraform Infrastructure ğŸ”¥ Explore Top Terraform Articles ğŸ”¹ AWS CDK - An Alternative? AWS Cloud Development Kit (AWS CDK) is an open-source framework for provisioning AWS infrastructure using code in languages like TypeScript, Python, Java, C#, Go. AWS CDK uses CloudFormation to deploy resources safely and repeatedly.\nğŸ“– Free resources to learn:\nğŸ¥ AWS CDK Course for Beginners ğŸ“„ Official AWS CDK Documentation ğŸ“‚ AWS CDK Examples ğŸ”¥ Explore Top AWS Articles ğŸ“Œ Conclusion Terraform is the leading tool for Infrastructure-as-Code, providing flexibility and powerful automation capabilities across multiple cloud platforms. If you work extensively with AWS and want to deploy using programming languages, AWS CDK is also a viable option to consider.\nDepending on project requirements, you can choose the appropriate tool to manage infrastructure more effectively. ğŸš€\nğŸ‘‰ Next step: Learn about Configuration Management - the process of managing, monitoring, and automating system, software, and infrastructure configurations to ensure consistency, stability, and easy control throughout their lifecycle. It helps track and control changes, reduce errors from manual configuration, and support rapid deployment. Popular tools include Ansible, Puppet, Chef, and SaltStack.\n","date":"2025-02-24T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-eleven.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-eleven/","title":"Infrastructure Provisioning with Terraform ğŸŸªğŸ”³"},{"content":"ğŸ” What is Logs Management? Logs management is the process of collecting, aggregating, analyzing, storing, and retrieving logs from applications and infrastructure systems. Logs contain critical information about system activity, helping detect incidents, optimize performance, and ensure security compliance.\nğŸš€ Popular Logs Management Tools Elastic Stack (ELK Stack) ğŸ“ Overview: Elastic Stack, formerly known as the ELK Stack, includes Elasticsearch (search and analytics), Logstash (data processing), Kibana (visualization), and Beats (data collection). It is a popular solution for logs management with high scalability.\nğŸ”¹ Key features:\nReal-time log search and analysis. Supports multiple data formats. Scales well for enterprise environments. Provides a visual interface with Kibana. Use Elastic Stack to collect logs from web servers, analyze errors, and create dashboards that track traffic patterns.\nğŸ“š Useful resources:\nğŸ”— Elastic Stack homepage ğŸ¥ Elastic Stack overview Loki ğŸ“ Overview: Loki is a log aggregation system developed by Grafana Labs, optimized for Kubernetes and containers. Loki stores log labels instead of full-text indexes, saving resources.\nğŸ”¹ Key features:\nTight integration with Grafana. Uses LogQL, a query language similar to PromQL. Optimized for Kubernetes and container environments. Resource-efficient compared to other solutions. Use Loki to track logs from containers in Kubernetes to detect application errors quickly.\nğŸ“š Useful resources:\nğŸ”— Loki homepage ğŸ“– Loki documentation Graylog ğŸ“ Overview: Graylog is an open-source logs management platform that supports real-time log collection, storage, and analysis. It provides a friendly web interface and supports multiple log data types.\nğŸ”¹ Key features:\nSupports log collection protocols such as Syslog and GELF. Powerful search interface. Alerting capabilities for incident detection. Real-time log queries. Use Graylog to monitor security system logs and detect intrusion behavior.\nğŸ“š Useful resources:\nğŸ”— Graylog homepage ğŸ¥ Graylog usage guides ğŸ”¥ Example Code Below is an example of sending logs to a log collection system using JavaScript:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 const winston = require(\u0026#39;winston\u0026#39;); const logger = winston.createLogger({ level: \u0026#39;info\u0026#39;, format: winston.format.json(), transports: [ new winston.transports.Console(), new winston.transports.File({ filename: \u0026#39;app.log\u0026#39; }) ] }); // Write logs logger.info(\u0026#39;Application started successfully\u0026#39;); logger.warn(\u0026#39;Warning: Invalid input data\u0026#39;); logger.error(\u0026#39;Error: Unable to connect to the database\u0026#39;); âœ… Conclusion Logs management plays a vital role in monitoring systems and resolving incidents quickly. Tools such as Elastic Stack, Loki, and Graylog provide powerful solutions for log collection, analysis, and visualization. Choosing the right tool will help improve operational efficiency. ğŸš€\nğŸ‘‰ Next step: Learn about Container Orchestration - the process of automatically managing, deploying, scaling, and coordinating containers in infrastructure environments, ensuring availability, scalability, and optimized resource usage. Common tools for container orchestration include Kubernetes, Docker Swarm, and Apache Mesos.\n","date":"2025-02-24T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-sixteen.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-sixteen/","title":"Logs Management ğŸ“œ"},{"content":"ğŸ” What is Secret Management? Secret Management is the process of protecting, storing, and securely distributing sensitive information such as passwords, API keys, and certificates in an organization\u0026rsquo;s information technology system. It helps prevent unauthorized access while ensuring authorized systems and users can use the information when needed.\nSecret Management typically includes features:\nData encryption during storage and transmission. Access control, only allowing authorized people or systems to access. Key rotation mechanism to change passwords periodically. Integration with DevOps systems to automate security processes. ğŸ”— Additional References:\nğŸ“„ How to manage secrets in web applications ğŸ“„ Why DevSecOps needs secret management ğŸ¥ DevOps tips for managing secrets in production environments ğŸ›ï¸ HashiCorp Vault HashiCorp Vault is a secret management tool that helps protect sensitive data such as passwords, API keys, and encryption keys.\nğŸ”‘ Key Features: Centralized management helps easily control secrets. Supports multiple authentication methods such as LDAP, Kubernetes. Provides dynamic secrets helps create temporary secrets when needed. Strong data encryption during storage and transmission. ğŸ”— Examples:\nStore and manage TLS certificates for a microservices architecture.\nIntegrate with Kubernetes to provide dynamic secrets for Pods each time they start.\nCreate temporary passwords for databases to reduce the risk of information leakage.\nğŸ›  Practical Examples: 1ï¸âƒ£ Provision dynamic passwords for PostgreSQL using Vault\nSuppose you have a PostgreSQL database and want to provision a temporary account:\n1 vault write database/creds/postgres-role This command will create a new account with limited lifetime.\n2ï¸âƒ£ Use Vault to manage API keys in Node.js applications\nYou can retrieve API keys from Vault in your source code:\n1 2 3 const { execSync } = require(\u0026#39;child_process\u0026#39;); const secret = execSync(\u0026#39;vault kv get -field=value secret/my-api-key\u0026#39;).toString(); console.log(`API Key: ${secret}`); ğŸ”— Useful Resources:\nğŸŒ HashiCorp Vault Homepage ğŸ› ï¸ HashiCorp Vault Source Code on GitHub ğŸ¥ HashiCorp Vault Introduction in 180 seconds ğŸ¥ HashiCorp Vault Tutorial for Beginners â˜ï¸ Cloud Secret Management Tools ğŸ”¥ AWS Secrets Manager Provides secure secret storage and management service on AWS with automatic password rotation capability and integration with other AWS services.\nğŸŒ Google Cloud Secret Manager Secret management solution on Google Cloud, allowing automatic password rotation and easy access control.\nğŸ”· Azure Key Vault Microsoft Azure service that helps securely store and manage keys, passwords, and digital certificates.\nğŸ”— Examples:\nAWS Secrets Manager: Store API keys of a web application, ensuring API keys are not exposed in source code.\nHashiCorp Vault: Manage database access passwords for PostgreSQL.\nAzure Key Vault: Store and secure application encryption keys.\nğŸ›  Practical Examples: 1ï¸âƒ£ Use AWS Secrets Manager to manage API keys\nSuppose you have a web application that needs to access a third-party service through an API key. Instead of storing the API key in source code, you can store it in AWS Secrets Manager and call it when needed:\n1 aws secretsmanager get-secret-value --secret-id my-api-key 2ï¸âƒ£ Create dynamic secrets with HashiCorp Vault\nHashiCorp Vault can create temporary passwords for databases to enhance security. For example, you can create a temporary account for PostgreSQL:\n1 vault write database/creds/my-role ğŸ”— Useful Resources:\nğŸ“„ AWS Secrets Manager â€“ AWS Secret Management Service ğŸ“„ Google Cloud Secret Manager â€“ Google Cloud Secret Management Service ğŸ“„ Azure Key Vault â€“ Azure Key and Secret Management Service ğŸ¥ AWS Secrets Manager Demo â€“ AWS Secrets Manager Tutorial ğŸ¥ Google Cloud Secret Manager â€“ Google Cloud Secret Manager Introduction ğŸ¥ Azure Key Vault and How to Use â€“ Azure Key Vault Tutorial ğŸ” Sealed Secrets Sealed Secrets is a tool for Kubernetes that helps encrypt sensitive data into SealedSecrets, which can be safely stored even in public environments like GitHub.\nğŸ› ï¸ How it works: Encryption: User creates a SealedSecret from a Kubernetes Secret. Storage: SealedSecret can be committed to Git. Decryption: Only the Kubernetes Controller in the cluster can decrypt and restore it to a regular Kubernetes Secret. ğŸ’¡ Highlights:\nUses asymmetric encryption ensuring only the controller can decrypt data. Supports GitOps helps manage secrets safely in Git repository. Easy integration with Kubernetes to protect sensitive data. ğŸ”— Useful Resources:\nğŸ› ï¸ Sealed Secrets on GitHub ğŸ“„ Sealed Secrets Documentation ğŸ”„ Integrating Secret Management into CI/CD CI/CD tools like Azure DevOps, Travis CI, and AWS CodePipeline support secret management by integrating with Secret Management systems to protect sensitive information during deployment.\nğŸ—ï¸ Azure DevOps Azure DevOps provides Azure Key Vault to securely store and manage secrets. Pipelines in Azure DevOps can retrieve secrets from Key Vault for use during deployment.\nğŸš€ Travis CI Travis CI supports environment variable encryption, helping protect API keys and sensitive information during builds.\nğŸŒ©ï¸ AWS CodePipeline AWS CodePipeline can integrate with AWS Secrets Manager to retrieve secrets during application deployment.\nğŸ¯ Conclusion Secret management plays an important role in modern system security. Using tools such as HashiCorp Vault, AWS Secrets Manager, Google Cloud Secret Manager, Azure Key Vault, Sealed Secrets, Azure DevOps, Travis CI, and AWS CodePipeline helps ensure the safety of sensitive information, supports secure DevOps deployment, and complies with security standards.\nğŸ‘‰ Next step: Monitor infrastructure Infrastructure Monitoring - the process of tracking and analyzing the performance, availability, and status of information technology infrastructure components such as servers, networks, storage, databases, and cloud computing services, helping to detect incidents early, optimize resources, and ensure stable system operation. ğŸš€\n","date":"2025-02-24T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-fourteen.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-fourteen/","title":"Secret Management ğŸ”’"},{"content":"ğŸš€ What is Serverless? Serverless is a cloud computing model where service providers fully manage the infrastructure, allowing developers to focus solely on writing code. The system automatically allocates resources based on demand and charges only for actual resource usage. Serverless architecture is commonly applied for microservices applications, event processing and helps minimize operational costs.\nğŸ“– Free resources to learn:\nğŸ“„ What is Serverless? ğŸ¥ Introduction to Serverless ğŸŒ Great articles about Serverless âš¡ AWS Lambda AWS Lambda is a serverless service from AWS that allows running code without managing servers. Lambda automatically scales based on demand, supports multiple programming languages, and easily integrates with other AWS services. It\u0026rsquo;s suitable for data processing, task automation, building microservices.\nğŸ–¥ï¸ Example: Deploying a function on AWS Lambda\n1 2 3 4 5 6 import json def lambda_handler(event, context): return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Hello from AWS Lambda!\u0026#39;) } ğŸ“– Free resources to learn:\nğŸ”— Introduction to AWS Lambda ğŸ¥ AWS Lambda Tutorial from A-Z ğŸŒ Great articles about AWS Lambda ğŸŒ Cloudflare Cloudflare is a company that provides CDN, security, performance optimization services for websites. Cloudflare acts as a reverse proxy, helping to speed up page loading and protect websites from attacks. The company was founded in 2009 and went public in 2019.\nğŸ“– Free resources to learn:\nğŸ”— Cloudflare Homepage ğŸ¥ Introduction to Cloudflare ğŸŒ Great articles about Cloudflare ğŸŒ Vercel Vercel is a frontend deployment platform that helps deploy web applications to the cloud quickly. It supports React, Next.js, Vue, Angular, integrates with GitHub, and allows deployment with just a push command.\nğŸ“– Free resources to learn:\nğŸ”— Vercel Homepage ğŸ“– Official Vercel Documentation ğŸ¥ Vercel Usage Guide ğŸŒ Great articles about Vercel ğŸ“Œ Conclusion Serverless helps automate deployment, reduce costs, and easily scale. Popular platforms:\nAWS Lambda: Event processing without servers. Cloudflare: CDN and website security. Vercel: Fast frontend deployment. Platform selection depends on your needs, technology, and budget. ğŸš€\nğŸ‘‰ Next step: Learn about Provisioning - the process of providing and configuring resources (servers, networks, storage, accounts) so that systems or applications can operate effectively.\n","date":"2025-02-24T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-ten.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-ten/","title":"Serverless and Related Platforms â˜ï¸"},{"content":"Setting up important network components This article will help you understand important network components:\nğŸ”¹ Forward Proxy\nğŸ”¹ Reverse Proxy\nğŸ”¹ Load Balancer\nğŸ”¹ Firewall\nğŸ”¹ Caching Server\nğŸ”¹ Web Server\nâš–ï¸ Load Balancer Load Balancer works like a \u0026ldquo;traffic cop\u0026rdquo; standing in front of servers and directing client requests to appropriate servers. This helps optimize speed, efficiently utilize resources, and avoid overload situations.\nğŸ”¹ If a server fails, the Load Balancer will redirect traffic to the remaining servers.\nğŸ”¹ Can be deployed with algorithms like Round Robin, Least Connections, IP Hash\u0026hellip;\nğŸ” Example Load Balancer configuration with Nginx: 1 2 3 4 5 6 7 8 9 10 11 upstream backend_servers { server backend1.example.com; server backend2.example.com; } server { listen 80; location / { proxy_pass http://backend_servers; } } ğŸ“š Further reading:\nğŸ“„ What is Load Balancing?\nğŸ“„ Load Balancing Algorithms\nğŸ“„ Nginx Reverse Proxy \u0026amp; Load Balancing\nğŸ¥ Video: How does Load Balancer work?\nğŸ” Forward Proxy Forward Proxy is an intermediary server standing between client and internet, forwarding requests from client to destination server. It helps with anonymity, security, access control, and content caching.\nğŸ”¹ Commonly used in enterprise networks to monitor and control access.\nğŸ”¹ Supports bypassing censorship and geographical restrictions.\nğŸ” Example Forward Proxy configuration with Squid: 1 2 3 4 5 6 7 8 9 10 11 apt update \u0026amp;\u0026amp; apt install squid -y # Edit configuration file nano /etc/squid/squid.conf # Add simple configuration http_access allow all http_port 3128 # Restart service systemctl restart squid ğŸ“š Further reading:\nğŸ“„ What is Forward Proxy?\nğŸ“„ Forward Proxy vs Reverse Proxy comparison\nğŸ¥ Video: How does Proxy work?\nğŸ”„ Reverse Proxy Reverse Proxy is an intermediary server that receives requests from clients and forwards them to appropriate backend servers. It helps with load balancing, caching, security, and SSL termination.\nğŸ”¹ Helps hide backend server information to enhance security.\nğŸ”¹ Supports traffic distribution and application performance optimization.\nğŸ” Example Reverse Proxy configuration with Nginx: 1 2 3 4 5 6 7 8 9 10 server { listen 80; server_name example.com; location / { proxy_pass http://backend_server; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; } } ğŸ“š Further reading:\nğŸ“„ What is Reverse Proxy?\nğŸ“„ Nginx Reverse Proxy Guide\nğŸ¥ Video: Reverse Proxy and practical applications\nğŸ”¥ Firewall Firewall is a network security device that monitors and filters incoming/outgoing traffic based on organization\u0026rsquo;s security policies.\nğŸ”¹ Prevents unauthorized access to internal systems.\nğŸ”¹ Supports data traffic control rules.\nğŸ” Example Firewall configuration with UFW (Uncomplicated Firewall): 1 2 3 4 5 6 7 8 9 10 11 # Install UFW apt install ufw -y # Open SSH port ufw allow 22/tcp # Block all other connections ufw default deny incoming # Enable UFW ufw enable ğŸ“š Further reading:\nğŸ“„ What is Firewall?\nğŸ“„ Common Firewall types\nğŸ¥ Video: Introduction to Firewall\nğŸŒ Nginx Nginx is an open-source web server, widely used for its ability to handle many concurrent connections with high performance.\nğŸ”¹ Supports web server, reverse proxy, load balancing, caching.\nğŸ”¹ Suitable for microservices systems and containers.\nğŸ” Example simple Nginx configuration: 1 2 3 4 5 6 server { listen 80; server_name example.com; root /var/www/html; index index.html; } ğŸ“š Further reading:\nğŸ“„ Nginx installation guide on Ubuntu\nğŸ¥ Video: Nginx in 100 seconds\nğŸ›ï¸ Apache Apache is one of the most popular web servers, supporting many extension modules and compatible with many operating systems.\nğŸ”¹ Easy to configure with .conf files.\nğŸ”¹ Supports SSL/TLS, user authentication, URL rewriting\u0026hellip;\nğŸ” Example simple Apache configuration: 1 2 3 4 5 6 7 8 \u0026lt;VirtualHost *:80\u0026gt; ServerName example.com DocumentRoot /var/www/html \u0026lt;Directory /var/www/html\u0026gt; AllowOverride All Require all granted \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; ğŸ“š Further reading:\nğŸ“„ Apache homepage\nğŸ¥ Video: Installing Apache on Ubuntu\nâœ… Conclusion ğŸ”¹ Load Balancer helps distribute traffic efficiently, reducing server load.\nğŸ”¹ Forward Proxy supports anonymity, caching, and access control from client.\nğŸ”¹ Reverse Proxy helps enhance security, caching, and optimize backend systems.\nğŸ”¹ Firewall protects systems from unauthorized access.\nğŸ”¹ Nginx \u0026amp; Apache are two popular web servers, serving web content and applications.\nBy implementing these components, you can build a powerful, secure, and efficient network system. ğŸš€\nğŸ‘‰ Next step: Learn about Networking Protocols - a set of rules and standards that define how devices in a network communicate with each other. They ensure data is transmitted accurately, securely, and efficiently between different systems.\n","date":"2025-02-23T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-seven.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-seven/","title":"Application Gateway ğŸŒ"},{"content":"ğŸŒ Cloud Providers Cloud service providers offer an API layer to abstract infrastructure, enabling resource deployment based on security standards and billing models. While cloud services actually run on servers in data centers, abstraction layers create the feeling of interacting with a single platform. The ability to quickly deploy, configure, and secure resources has made cloud a critical factor in the success and complexity of modern DevOps.\nğŸ“– Free resources to learn:\nğŸ“„ Cloud Service Provider ğŸ“„ What are Cloud Providers? ğŸŒ Great articles about Cloud â˜ï¸ AWS (Amazon Web Services) AWS has been the leading cloud computing platform since 2011, far ahead of Azure and Google Cloud. AWS provides over 200 services, operating on a global scale. AWS delivers flexible and cost-effective computing solutions, including: computing power, data storage, content distribution, etc.\nğŸ–¥ï¸ Example: Create an EC2 instance using AWS CLI\n1 aws ec2 run-instances --image-id ami-12345678 --count 1 --instance-type t2.micro --key-name MyKeyPair --security-groups MySecurityGroup ğŸ“– Free resources to learn:\nğŸ¥ 100 hours AWS course - 2024 ğŸ”— AWS Homepage ğŸ“„ Guide to creating AWS account ğŸŒ Great articles about AWS ğŸ’  Microsoft Azure Azure is Microsoft\u0026rsquo;s cloud computing platform, providing IaaS, PaaS, SaaS along with many services like analytics, AI, machine learning, security. Azure supports multiple tools and programming languages, helping businesses develop rapidly.\nğŸ–¥ï¸ Example: Deploy application on Azure App Service\n1 az webapp create --resource-group MyResourceGroup --plan MyAppServicePlan --name MyUniqueApp --runtime \u0026#34;PYTHON:3.8\u0026#34; ğŸ“– Free resources to learn:\nğŸ”— Azure Homepage ğŸ“– Microsoft Azure Guide ğŸ¥ Azure Fundamentals Certification (AZ-900) ğŸŒ Great articles about Azure â˜ï¸ Google Cloud Platform (GCP) Google Cloud provides over 150 services, running on the same infrastructure as Google products like Search, Gmail, YouTube. Services include: VMs, databases, AI/ML, Kubernetes, etc.\nğŸ–¥ï¸ Example: Create a VM on Google Cloud\n1 gcloud compute instances create my-instance --machine-type=e2-medium --image-project=debian-cloud --image-family=debian-11 ğŸ“– Free resources to learn:\nğŸ”— Google Cloud Homepage ğŸ“– 5 tips to become Google Cloud Certified ğŸ¥ Google Cloud Platform Course - 2023 ğŸŒ Great articles about Google Cloud ğŸŒŠ DigitalOcean DigitalOcean is a cloud infrastructure provider focused on simplicity, low cost, ease of use. DigitalOcean provides services like virtual machines (Droplets), databases, Kubernetes, object storage, suitable for startups and developers.\nğŸ–¥ï¸ Example: Create a Droplet on DigitalOcean using API\n1 curl -X POST -H \u0026#34;Content-Type: application/json\u0026#34; -H \u0026#34;Authorization: Bearer YOUR_TOKEN\u0026#34; -d \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;example-droplet\u0026#34;,\u0026#34;region\u0026#34;:\u0026#34;nyc3\u0026#34;,\u0026#34;size\u0026#34;:\u0026#34;s-1vcpu-1gb\u0026#34;,\u0026#34;image\u0026#34;:\u0026#34;ubuntu-20-04-x64\u0026#34;}\u0026#39; \u0026#34;https://api.digitalocean.com/v2/droplets\u0026#34; ğŸ“– Free resources to learn:\nğŸ”— DigitalOcean Homepage ğŸ“„ DigitalOcean\u0026rsquo;s Hacktoberfest ğŸ¥ Kubernetes on DigitalOcean Tutorial ğŸŒ Great articles about DigitalOcean ğŸ“Œ Conclusion Cloud service providers like AWS, Azure, GCP, DigitalOcean provide flexible solutions for all server, storage, AI, DevOps needs. Each platform has its own advantages:\nAWS: Comprehensive, most services available. Azure: Good integration with Microsoft ecosystem. GCP: Optimized for AI, big data. DigitalOcean: Simple, suitable for startups. Choosing the right platform depends on your goals, budget, technical requirements. ğŸš€\nğŸ‘‰ Next step: Learn about Serverless - a cloud computing model that allows running applications without managing servers. Cloud providers automatically allocate resources, scale, and charge based on actual resource usage, helping optimize costs and simplify deployment.\n","date":"2025-02-23T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-nine.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-nine/","title":"Cloud Services ğŸŒ©ï¸"},{"content":"ğŸ“¦ Containers, Docker and LXC Containers are lightweight, portable, and isolated environments that help package applications along with all their dependencies, ensuring consistent deployment across different environments. Container technology simplifies application deployment processes, supports microservices architecture models, and optimizes system resources.\nğŸ—ï¸ What are Containers? Containers are an operating system-level virtualization method that allows running multiple isolated applications on the same kernel. Unlike virtual machines (VMs) that require separate operating systems for each environment, containers only use the host operating system\u0026rsquo;s kernel, helping reduce resource costs and increase performance.\nğŸ¯ Key Characteristics of Containers ğŸ‹ï¸ Lightweight: Share kernel with host operating system, reducing resource consumption. ğŸš€ Portable: Run consistently across multiple platforms from personal computers to cloud. ğŸ”’ Isolated: Applications and libraries are packaged separately. ğŸ“ˆ High Performance: No need to boot separate operating systems like virtual machines. ğŸ³ Docker - The Most Popular Container Platform Docker is an open-source platform that helps automate application deployment using container technology. Docker helps package applications with all necessary libraries and configurations to run across different environments.\nâœ¨ Notable Features of Docker ğŸ“¦ Docker Engine: Tool for creating and running containers. ğŸ”„ Docker Compose: Manage multiple containers in one application. ğŸ—ï¸ Docker Hub: Repository for storing and sharing container images. ğŸ” Docker Usage Example: 1 docker run -d -p 80:80 nginx The above command will run an Nginx container on port 80.\nğŸ“š Useful Resources:\nğŸ“– Docker Documentation ğŸ¥ Docker in 5 Minutes ğŸ–¥ï¸ LXC - Linux Containers LXC (Linux Containers) is an operating system-level virtualization method that allows running multiple isolated Linux systems on the same kernel.\nğŸ› ï¸ LXC Characteristics: ğŸ—ï¸ Creates environments similar to virtual machines but with higher performance. âš¡ Faster startup compared to traditional VMs. ğŸ” Uses Linux technologies like cgroups and namespaces. ğŸ“Œ Example of Creating an LXC Container: 1 2 lxc-create -n my-container -t ubuntu lxc-start -n my-container -d ğŸ“š Useful Resources:\nğŸ“– LXC Homepage ğŸ¥ LXC Usage Guide ğŸ¯ Conclusion Containers help deploy applications quickly, efficiently, and save resources. Docker is a popular choice for application development, while LXC is more suitable for full operating system simulation. Choose the tool that fits your needs! ğŸš€\nğŸ‘‰ Next Step: Learn about Application Gateway - an application-layer traffic management service that helps optimize, secure, and control access flow between clients and backends. It can act as a reverse proxy, protecting the system and ensuring requests are processed correctly.\n","date":"2025-02-23T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-six.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-six/","title":"Containers, Docker and LXC ğŸ—ï¸"},{"content":"ğŸ–§ Networking Protocols Networking protocols are a set of standardized rules that help data be transmitted, received, and understood correctly across computer networks. They define the format, timing, sequence, and error control during data transmission. Some important protocols include:\nTCP/IP: The foundational protocol suite for Internet communication. HTTP/HTTPS: Hypertext transfer protocol used for the web. FTP/SFTP: File transfer protocols. SMTP/POP3/IMAP: Email transmission protocols. DNS: Domain name resolution protocol. DHCP: Automatic IP address allocation protocol. SSL/TLS: Data security protocols. UDP: Connectionless, fast transmission protocol. ğŸŒ Domain Name System (DNS) DNS (Domain Name System) is a domain name resolution system that helps convert memorable domain names (e.g., www.example.com) into IP addresses (192.168.1.1) that computers can understand.\nğŸ”¹ Example DNS configuration in Linux: 1 2 3 4 5 6 7 8 9 # Check DNS for a domain name nslookup example.com dig example.com # Edit hosts file to map domain names sudo nano /etc/hosts # Add the following line: 192.168.1.100 mycustomdomain.com ğŸ”— Reference resources:\nğŸ“„ How DNS works ğŸ¥ DNS explanation video ğŸŒ HTTP Protocol HTTP (Hypertext Transfer Protocol) is a data transmission protocol on the web following a request-response model.\nğŸ”¹ Example sending HTTP requests with cURL: 1 2 3 4 5 6 7 # Send GET request curl -X GET https://jsonplaceholder.typicode.com/posts/1 # Send POST request curl -X POST https://jsonplaceholder.typicode.com/posts \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;title\u0026#34;: \u0026#34;Hello\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;World\u0026#34;}\u0026#39; ğŸ”— Reference resources:\nğŸ“„ Learn about HTTP ğŸ¥ HTTP tutorial video ğŸ”’ HTTPS and Security (SSL/TLS) HTTPS is the secure version of HTTP, using SSL/TLS to encrypt data, ensuring safety during transmission over the Internet.\nğŸ”¹ Example setting up HTTPS with Nginx: 1 2 3 4 5 6 server { listen 443 ssl; server_name example.com; ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; } ğŸ”— Reference resources:\nğŸ“„ What is HTTPS? ğŸ¥ How HTTPS works video ğŸ”‘ SSH - Secure Connection SSH (Secure Shell) is a protocol that enables secure connection to remote servers.\nğŸ”¹ Example using SSH for remote connection: 1 2 3 4 5 # Connect to remote server ssh user@example.com # Copy files from server to local machine scp user@example.com:/path/to/file ./localfile ğŸ”— Reference resources:\nğŸ“„ SSH tutorial ğŸ¥ How SSH works video ğŸ¯ Conclusion Networking protocols are the foundation of all online systems, from web browsing to sending emails. Understanding and knowing how to use them helps improve system security and performance. Try applying the commands above to check and configure your system! ğŸš€\nğŸ‘‰ Next step: Learn about Cloud Providers - companies that provide cloud computing services, allowing individuals and businesses to access resources like servers, storage, databases, AI, and other services over the internet without investing in hardware infrastructure.\n","date":"2025-02-23T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-eight.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-eight/","title":"Networking Protocols ğŸ–§"},{"content":"ğŸŒ Translation in Progress We are gradually translating the entire website to English to serve our international readers better.\nCurrently Available in English: About page DevOps series (in progress) Selected technical articles Coming Soon: Complete DevOps tutorial series Docker optimization guides Nginx installation guides All technical content Thank you for your patience as we work to make all content accessible in English! ğŸš€\n","date":"2025-02-23T00:00:00Z","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/notice/","title":"Notice"},{"content":"ğŸŒ Source Code Hosting Services (Repo Hosting Services) When working in teams, you need a remote place to store source code so everyone can access it, create their own branches, and create or review pull requests. These services typically include issue tracking, code review, and continuous integration (CI/CD). Popular options include GitHub, GitLab, Bitbucket, and AWS CodeCommit.\nğŸ“š Free resources to learn more:\nğŸ”— GitHub ğŸ”— GitLab ğŸ”— BitBucket ğŸ¥ GitHub vs GitLab vs Bitbucket - Which one to choose? ğŸ™ GitHub GitHub is a Git-based source code management platform that provides cloud-based code repository hosting services. It supports features like bug tracking, task management, and project wikis. GitHub enables code review through pull requests, issue tracking, and supports collaborative programming with features like fork and star.\nGitHub supports both public and private repositories, making it a popular choice for both open-source projects and personal development. The GitHub ecosystem includes:\nğŸš€ GitHub Actions: Workflow automation. ğŸ“¦ GitHub Packages: Software package management. ğŸŒ GitHub Pages: Free static website hosting. ğŸ“š Free resources to learn more:\nğŸ—ºï¸ Git \u0026amp; GitHub Roadmap ğŸ”— GitHub Homepage ğŸ“– How to use Git in professional development teams ğŸ¥ What is GitHub? ğŸ“° Great articles about GitHub ğŸ¦Š GitLab GitLab is a comprehensive DevOps tool that provides Git repository management along with wikis, issue tracking, and built-in CI/CD features. It\u0026rsquo;s a complete DevOps platform covering all stages from planning, development, testing to deployment and monitoring.\nGitLab supports both cloud and self-hosted versions, suitable for organizations with high security requirements. Some notable GitLab features include:\nğŸ”„ Built-in CI/CD: Supports automated testing and deployment. ğŸ“¦ Container \u0026amp; Package Registry: Package management and storage. ğŸ” Source code security scanning: Detects vulnerabilities in code. ğŸ“š Free resources to learn more:\nğŸ”— GitLab Homepage ğŸ“– Official GitLab Documentation ğŸ¥ What is GitLab and why use it? ğŸ“° Great articles about GitLab ğŸ—ï¸ Bitbucket Bitbucket is Atlassian\u0026rsquo;s source code repository hosting service that supports both Git and Mercurial. It integrates tightly with other Atlassian tools like Jira and Trello, making project management easier. Bitbucket offers both cloud and self-hosted versions.\nSome notable Bitbucket features:\nğŸ” Code Review \u0026amp; Pull Requests: Supports code review. ğŸ”„ Bitbucket Pipelines: Built-in CI/CD. ğŸ“– Wiki \u0026amp; Issue Tracking: Documentation management and issue tracking. ğŸ” Free private repository support: Suitable for small teams. ğŸ“š Free resources to learn more:\nğŸ”— Bitbucket Homepage ğŸ“– Bitbucket Overview ğŸ“š Introduction to Git and Bitbucket ğŸ¥ Bitbucket Cloud Tutorial ğŸ“° Great articles about Bitbucket ğŸ“Œ Conclusion Choosing a source code repository hosting service depends on your development team\u0026rsquo;s needs. If you need a popular platform with a vast ecosystem, GitHub is a strong choice. If you want a fully integrated DevOps solution, GitLab would be more suitable. If you\u0026rsquo;re already using the Atlassian ecosystem, Bitbucket would be the best choice.\nConsider your project needs and desired level of integration to make the right decision! ğŸš€\nğŸ‘‰ Next step: Learn about Containers that help package applications along with all libraries, configurations, and dependencies to run consistently across different environments.\n","date":"2025-02-23T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-five.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-five/","title":"Source Code Hosting Services ğŸ±"},{"content":"ğŸ–¥ï¸ Terminal Knowledge Terminal is a text interface that allows users to interact with computer systems through CLI (Command Line Interface). It is an essential tool for system management, command execution, and task automation.\nğŸ“š Free Resources ğŸ“„ Article: What is CLI? ğŸ” Google Search â–¶ï¸ YouTube Search ğŸ”¹ Example:\n1 2 ls -l # List files in current directory pwd # Display current directory path ğŸ“Š Process Monitoring Process monitoring is the continuous observation and analysis of processes in IT systems to ensure performance, efficiency, and compliance. It helps track important metrics such as resource usage and behavior of individual processes or applications running in the system.\nğŸ† Recommended Tools ğŸŸ£ lsof - Lists information about files opened by processes. ğŸ“š Free Resources ğŸ“„ Lsof Cheat Sheet ğŸ“– lsof Documentation â–¶ï¸ Video: Linux Crash Course - lsof Command ğŸ“ Great Articles on Monitoring ğŸ”¹ Example:\n1 2 lsof -i :80 # List processes using port 80 ps aux # Display all running processes ğŸš€ Performance Monitoring Performance monitoring helps collect, analyze, and report key performance metrics from applications, networks, servers, and databases.\nğŸ† Recommended Tools ğŸŸ£ vmstat - Virtual memory and system performance monitoring tool. ğŸ“š Free Resources ğŸ“– Linux Commands: Exploring Virtual Memory with vmstat ğŸ“„ vmstat Documentation â–¶ï¸ vmstat Tutorial ğŸ“ Great Articles on Monitoring ğŸ”¹ Example:\n1 vmstat 5 10 # Update system status every 5 seconds for 10 times ğŸŒ Networking Tools Networking tools support monitoring, analyzing, troubleshooting, and managing network systems.\nğŸ† Recommended Tools ğŸŸ£ Wireshark - Deep packet analysis. ğŸŸ£ Nmap - Network scanning and security testing. Ping - Basic connectivity testing. Traceroute - Determine packet path through network. Netstat - Display network connections. Tcpdump - Command-line packet capture and analysis. Iperf - Network performance testing. Netcat - Perform various network tasks. Nslookup/Dig - DNS queries. PuTTY - Remote connection via SSH or Telnet. ğŸ”¹ Example:\n1 2 ping google.com # Test connection to Google nmap -sS 192.168.1.1 # Scan internal server ports âœ‚ï¸ Text Manipulation Tools that support editing, processing, and converting text data.\nğŸ† Recommended Tools ğŸŸ£ sed - Stream editor for data manipulation. ğŸŸ£ awk - Pattern scanning and data extraction. ğŸŸ£ grep - Text search using regular expressions. cut, sort, tr, uniq - Supporting commands for text data processing. ğŸ”¹ Example:\n1 2 grep \u0026#34;error\u0026#34; logfile.txt # Find \u0026#34;error\u0026#34; in logfile.txt awk \u0026#39;{print $1}\u0026#39; data.txt # Get first column from data.txt âš¡ Bash Scripts Bash is a powerful shell on Unix/Linux that helps execute commands and automate tasks.\nğŸ”¹ Example:\n1 2 #!/bin/bash echo \u0026#34;Hello, World!\u0026#34; âœï¸ Editors Text editors are essential tools for editing and managing text files.\nğŸ† Recommended Tools ğŸŸ£ Vim - Powerful, highly customizable, suitable for programmers. ğŸŸ£ Emacs - Flexible with many supporting plugins. Sublime Text - High speed, user-friendly interface. Visual Studio Code - Open source, supports debugging, extensions, integrated development tools. ğŸ”¹ Example:\n1 2 vim myfile.txt # Open file with Vim nano myfile.txt # Open file with Nano ğŸ”š Conclusion Understanding and mastering these tools helps you work more efficiently in Linux and DevOps environments. Tools ğŸŸ£ marked are the most popular and powerful ones, recommended by many experts. You can learn more through the accompanying free resources. If there\u0026rsquo;s anything that needs clarification or addition, please provide feedback so I can update accordingly!\nğŸ‘‰ Next step: Advance your knowledge of Version Control Systems to effectively track, manage, and collaborate on source code.\n","date":"2025-02-23T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-three.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-three/","title":"Terminal Knowledge ğŸ“Ÿ"},{"content":"ğŸ”„ Version Control Systems Version control systems (VCS) are tools that help track changes to source code and files over time. They support team collaboration, manage change history, and maintain multiple versions of source code. There are two main types of VCS:\nCentralized VCS (CVCS): Uses a central repository, examples include Subversion (SVN), CVS. Distributed VCS (DVCS): Each user has a complete copy of the repository, including the entire history. The most popular example is Git. Git is a powerful distributed version control system that allows offline work, supports fast branching and merging operations, enhancing collaboration capabilities.\nğŸ› ï¸ Git - The Most Popular Version Control Tool ğŸ”¹ Installing Git If you haven\u0026rsquo;t installed Git yet, you can download it from git-scm.com or use the following commands:\n1 2 3 sudo apt install git # Ubuntu/Debian yum install git # CentOS/RHEL brew install git # macOS Verify Git installation:\n1 2 3 4 git --version # output: # git version 2.47.1.windows.1 ğŸš€ Basic Git Commands Below are common Git commands, organized from basic to advanced:\nInitialization \u0026amp; Configuration 1 git init # Initialize Git repository 1 2 git config --global user.name \u0026#34;Your Name\u0026#34; # Configure name git config --global user.email \u0026#34;email@example.com\u0026#34; # Configure email Working With Repository 1 git clone \u0026lt;repo_url\u0026gt; # Clone a remote repository to local machine 1 git status # Check file status Adding \u0026amp; Saving Changes 1 git add \u0026lt;file\u0026gt; # Add file to staging area 1 git commit -m \u0026#34;Change description\u0026#34; # Save changes to history Working With Remote Repository 1 git remote add origin \u0026lt;repo_url\u0026gt; # Link remote repository 1 git push -u origin main # Push changes to main branch 1 git pull origin main # Update latest changes from remote repository Working With Branches 1 git branch new-feature # Create new branch 1 git checkout new-feature # Switch to new branch 1 git merge new-feature # Merge branch into current branch Tracking History 1 git log # View commit history 1 git diff # Compare changes between versions ğŸ“š Free Git Learning Resources ğŸ“– Official Git Documentation ğŸ“„ Git Cheat Sheet â–¶ï¸ Git Tutorial Video for Beginners ğŸ“ Article: What is Version Control System? ğŸ”š Conclusion Using Git makes source code management easier, supports effective team collaboration, and protects important project data. Understanding and mastering Git is an essential skill for every programmer.\nğŸ‘‰ Next step: Learn about GitHub \u0026amp; GitLab to manage Git repositories on cloud platforms.\n","date":"2025-02-23T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-four.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-four/","title":"Version Control Systems ğŸ› ï¸"},{"content":"ğŸ“Œ Why is Linux important in DevOps? Linux is the foundation of most server systems, containers (Docker, Kubernetes), and cloud platforms. DevOps professionals need to master Linux to:\nâœ… Manage servers effectively. âœ… Write automation scripts. âœ… Handle files, users, and processes. âœ… Optimize systems and security. âš™ï¸ What is an Operating System? An operating system (OS) is software that manages computer hardware and software resources, providing common services for programs. It acts as an intermediary between applications and hardware, handling tasks such as:\nğŸ”¹ Memory management. ğŸ”¹ Process scheduling. ğŸ”¹ File system management. ğŸ”¹ Device control. ğŸŒ Popular operating systems: ğŸ’» Personal computers: Windows, macOS, Linux (Ubuntu, Fedora,\u0026hellip;) ğŸ“± Mobile devices: iOS, Android ğŸ–¥ï¸ Servers: Ubuntu Server, Red Hat Enterprise Linux, Windows Server Each operating system has different characteristics, interfaces, and compatibility capabilities. They play crucial roles in system security, performance optimization, and providing consistent user experiences.\nğŸ› ï¸ Basic Linux Commands Here are some important Linux commands:\nğŸ” System Information 1 2 3 uname -a # Display operating system information uptime # System uptime free -m # Check RAM memory ğŸ“‚ File \u0026amp; Directory Management 1 2 3 ls -l # List files with detailed information mkdir mydir # Create new directory rm -rf mydir # Delete directory and its contents ğŸš€ Process Management 1 2 3 top # Display running processes ps aux # List all processes kill -9 PID # Stop process by PID ğŸ‘¤ User Management 1 2 3 whoami # View current user sudo useradd devops # Create new user sudo passwd devops # Set password for user ğŸ“œ Bash Script for System Resource Monitoring 1 2 3 4 5 6 7 8 9 10 #!/bin/bash echo \u0026#34;==== System Information ====\u0026#34; uname -a echo \u0026#34;==== System Uptime ====\u0026#34; uptime echo \u0026#34;==== RAM Memory ====\u0026#34; free -m â–¶ï¸ How to run the script: 1 2 chmod +x system_check.sh # Grant execute permission to script ./system_check.sh # Run script in terminal ğŸ“š Learning Resources Here are some free resources to learn more about operating systems:\nğŸ“– Operating Systems - Wiki ğŸ“– All you need to know about OS ğŸ“– Learn Operating Systems ğŸ¥ What are Operating Systems? ğŸ¥ Operating Systems ğŸ¯ Conclusion âœ… Linux is a mandatory skill in DevOps. âœ… Learn to use terminal \u0026amp; Bash scripting. ğŸ‘‰ Next step: Learn more about terminal and CLI usage to work effectively with systems.\n","date":"2025-02-22T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-two.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-two/","title":"Learning Linux \u0026 Operating Systems ğŸ–¥ï¸"},{"content":"ğŸ“Œ Why do you need to choose a programming language? In DevOps, you will need to use programming languages to:\nâœ… Write automation scripts. âœ… Manage servers and cloud. âœ… Create tools to support CI/CD. âœ… Build and deploy Infrastructure as Code (IaC). Choosing the right language helps you work more efficiently with systems, automate many processes, and improve software development speed.\nğŸ”¥ Suitable languages for DevOps ğŸ Python (Main recommendation) ğŸ”¹ Reasons to choose Python: Easy-to-read syntax, easy to learn. Rich libraries supporting automation like fabric, paramiko, boto3 (AWS SDK), pyinfra. Strong support in Cloud management (AWS, GCP, Azure). ğŸ”¹ Practical applications: Write automated code deployment scripts. Create server management bots. Build system management APIs. ğŸ“ Example: Automated SSH deployment script with Paramiko 1 2 3 4 5 6 7 8 9 10 11 import paramiko def deploy_code(host, user, password, command): client = paramiko.SSHClient() client.set_missing_host_key_policy(paramiko.AutoAddPolicy()) client.connect(hostname=host, username=user, password=password) stdin, stdout, stderr = client.exec_command(command) print(stdout.read().decode()) client.close() deploy_code(\u0026#39;192.168.1.100\u0026#39;, \u0026#39;ubuntu\u0026#39;, \u0026#39;yourpassword\u0026#39;, \u0026#39;git pull origin main \u0026amp;\u0026amp; systemctl restart app\u0026#39;) ğŸ–¥ï¸ Bash (Need to know basics) ğŸ”¹ Reasons to choose Bash: The most popular shell script on Linux. Helps you work quickly with the system. Optimized for server management and small task automation. ğŸ”¹ Practical applications: Write automated server update scripts. Create periodic cron jobs. Manage users and permissions on Linux. ğŸ“ Example: Automated server update script 1 2 #!/bin/bash sudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y ğŸš€ Go (Golang) (If working with Kubernetes) ğŸ”¹ Reasons to choose Go: High performance, easy to compile into compact binaries. Kubernetes and many DevOps tools like Terraform are written in Go. ğŸ”¹ Practical applications: Write container management tools. Create plugins for Kubernetes. Build custom DevOps tools. ğŸ“ Example: Display system information with Go 1 2 3 4 5 6 7 8 9 10 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { hostname, _ := os.Hostname() fmt.Println(\u0026#34;Hostname:\u0026#34;, hostname) } âš™ï¸ Groovy (If working with Jenkins) ğŸ”¹ Reasons to choose Groovy: The main language for writing pipelines in Jenkins. Flexible syntax, easy to extend and integrate with Java. ğŸ”¹ Practical applications: Write CI/CD pipelines for Jenkins. Create system management scripts. Automate build, test, deploy steps. ğŸ“ Example: Basic pipeline in Jenkinsfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 pipeline { agent any stages { stage(\u0026#39;Build\u0026#39;) { steps { echo \u0026#39;Building the project...\u0026#39; sh \u0026#39;mvn clean package\u0026#39; } } stage(\u0026#39;Test\u0026#39;) { steps { echo \u0026#39;Running tests...\u0026#39; sh \u0026#39;mvn test\u0026#39; } } stage(\u0026#39;Deploy\u0026#39;) { steps { echo \u0026#39;Deploying application...\u0026#39; sh \u0026#39;./deploy.sh\u0026#39; } } } } ğŸ¯ Conclusion âœ… Python + Bash is the best choice to start with DevOps. âœ… If working with Kubernetes, learn Go as well. âœ… If working with Jenkins, learn Groovy to write pipelines. ğŸ‘‰ Next step: Learn the basics of Linux \u0026amp; operating systems.\n","date":"2025-02-21T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-step-one.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-step-one/","title":"Choosing a Programming Language ğŸ¤—"},{"content":"Understanding DevOps DevOps is the combination of software development and system operations, aimed at enhancing collaboration and automation in the software development and deployment process.\nLearn a Programming Language Mastering at least one programming language is essential for effective automation and system management.\nPopular Languages\nPython Go Ruby Master Operating System Knowledge Linux: Popular operating system in server environments. Windows: Important in enterprises using Microsoft infrastructure. Learn About Computer Networks and Security Key topics to focus on:\nNetwork Protocols: HTTP, HTTPS, FTP, TCP/IP. Network Security: Firewalls, VPN, SSL/TLS. Use Source Code Management Tools Effective source code management is a crucial element in DevOps.\nGit: Popular version control system. Understand Configuration Management and Infrastructure as Code Configuration automation helps maintain consistency and efficiency.\nAnsible: Automation tool. Terraform: Infrastructure management by defining it in source code. Master Containerization and Orchestration Docker: Popular container platform. Kubernetes: Powerful container orchestration system. Set Up and Manage CI/CD Jenkins: Open-source automation server. GitLab CI/CD: Effective CI/CD support. Monitoring and Logging Prometheus: Monitoring system. ELK stack: Log analysis toolkit. Learn About Cloud Services Popular providers:\nAWS Google Cloud Microsoft Azure Conclusion Becoming a DevOps engineer requires broad knowledge and deep practical skills. Keep learning and practicing continuously to achieve your goals.\nNote: This roadmap is compiled from multiple sources and real-world experience, aiming to provide you with the most comprehensive and detailed view of the path to becoming a DevOps engineer. ğŸ¯ğŸš€\nDevOps Roadmap 2025 ","date":"2025-02-20T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-roadmap.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-roadmap/","title":"DevOps Engineer Roadmap ğŸ˜"},{"content":"Introduction to DevOps DevOps is a methodology that combines software development (Development - Dev) and system operations (Operations - Ops) to optimize the process of developing, deploying, and operating applications. DevOps helps development and operations teams work together more effectively through tools, automated processes, and collaborative culture.\nWhy is DevOps Important? Accelerated Development Speed DevOps helps automate processes like testing, deployment, and monitoring, reducing time-to-market for products.\nImproved Product Quality Integration of automated testing and CI/CD helps detect bugs early, minimizing risks during software deployment.\nEnhanced Reliability Monitoring and logging tools help quickly identify issues, reduce downtime, and ensure systems operate stably.\nBetter Team Collaboration DevOps breaks down barriers between development and operations teams, creating a more effective collaborative work environment.\nKey Components of DevOps CI/CD (Continuous Integration \u0026amp; Continuous Deployment) CI/CD automates the process of source code integration, testing, and deployment, minimizing errors when releasing products to production environments.\nInfrastructure as Code (IaC) IaC allows infrastructure management as code, making it easy to deploy and scale systems.\nMonitoring and Logging Tools like Prometheus, Grafana, ELK Stack help monitor and analyze logs to quickly handle incidents.\nContainerization and Orchestration Docker and Kubernetes help package, manage, and scale applications flexibly.\nPopular DevOps Tools CI/CD: Jenkins, GitHub Actions, GitLab CI/CD IaC: Terraform, Ansible, CloudFormation Monitoring: Prometheus, Grafana, ELK Stack Container \u0026amp; Orchestration: Docker, Kubernetes Source Code Management: Git, GitHub, GitLab Conclusion DevOps is an important methodology that helps improve development speed, product quality, and optimize system operations. In the upcoming articles of this series, we will explore each aspect of DevOps in depth, from CI/CD, Infrastructure as Code to system monitoring.\nDocker Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Use Node.js as the base FROM node:18 # Set working directory in container WORKDIR /app # Copy package.json and install dependencies COPY package.json . RUN npm install # Copy entire source code into container COPY . . # Expose port 3000 for the application EXPOSE 3000 # Command to run the application CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] ğŸ’¡ Follow the blog to stay updated with the latest DevOps articles!\n","date":"2025-02-19T00:00:00Z","image":"https://tech.nguuyen.io.vn/images/devops/devops-intro.webp","permalink":"https://tech.nguuyen.io.vn/en/posts/devops/devops-intro/","title":"What is DevOps?"}]